# Designing Korean hate speech detection models with Auto-labeling using Semi-supervised Multi-task learning: Sustainable approach
- Thesis in Language Technology  Master's program, Uppsala University

## Keywords
\# Hate speech detection # Semi-supervised learning # Multi-task learning # Masked langauge modeling
\# Auto-labeling # Synthetic data # Data augmentation # Sustainability

## Data
- Korean hate/non-hate speech texts
- Training: Labeled + Unlabeled
- Test: Labeled

<img width="450" height="250" alt="data" src="https://github.com/user-attachments/assets/160b804d-110f-4235-a255-1743ef9b5fc8" />

## Language model
- Pre-trained language models: KoBERT, KoELECTRA

## Experiments

<img width="580" height="450" alt="experimental workflow" src="https://github.com/user-attachments/assets/7f53f18c-47a8-4b56-8dc1-8f2d178fbb0c" />

## Results
<img width="800" height="500" alt="results" src="https://github.com/user-attachments/assets/c88c5202-3293-4134-beeb-7776074c095b" />


## Short conclusion
- The experimental results demonstrated that the proposed semi-supervised multi-task learning framework improved the performance of both KoBERT and KoELECTRA for the detection task. In addition, the models successfully generated useful pseudo-labeled data for the auto-labeling task, which in turn contributed to data augmentation and produced consistent, stable results overall.

- It raises important considerations regarding cost-effectiveness and sustainability in machine learning and artificial intelligence research.
